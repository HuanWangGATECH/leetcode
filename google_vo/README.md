## 1. NG https://www.1point3acres.com/bbs/thread-831287-1-1.html


12月初面的五轮狗狗

BQ：天竺姐姐 问了一堆有的没的，讲了讲自己实习时候的故事

VO1: 国人大哥，先是问了如何在树里找root到node的path，然后问从start node到end node的path如何找。这道题地里面经出现过好多次了

VO2: ABC姐姐，从定义leaf node和internal node开始实现一个rope，follow up是实现插入和删除某一段下标这两个method，第二个follow up就讲了个思路来不及写了

VO3: 国人姐姐，一个grid上面有房子和树，要求每一栋房子周围都要种1棵树，且所有树必须不同行不同列。follow up是如果同行或同列的有一个上限，怎么处理？这一轮回答的不好，follow up同样只来得及讲个思路

VO4: 东南亚姐姐，给一堆字符串，问能不能从每一个字符串选出一个字符，拼出target的字符串

蹭热度求问NG如何compete啊啊啊啊不想被狗lowball...实习结束拿到offer以‍‌‍‌‍‌‌‍‌‍‍‌‍‍‍‍‌‌后原地躺平，一直到11月份才想着要不要面一点公司。之前实习的return虽然从数字上比lowball高不少，但是毕竟已经过期了快三个月了...还有什么办法可以拿来和狗家compete吗？回复必加米！！

## 2. Intern https://www.1point3acres.com/bbs/thread-830949-1-1.html

一面：考的是排序和二分，三道题层层递进，前面两题口述算法和复杂度，只有最后一个问题需要写代码；

二面：考的是普通树删叶子，两个follw-up，分别是最新出现的叶子结点先删、最新出现的叶子结点后删


## 3. NG https://www.1point3acres.com/bbs/thread-831681-1-1.html

第一轮BQ 都是常规题（而且基本都忘了）就不写了

第二轮

Given training data as list of tokenized words
[[“I”, “am”, “a”, “person”],
   [“I”, “am”, “good”],
   [“a”, “person”]]
write a predictor that predict a word’s most frequent bigram
e.g. predict(“I”) -> “am”
  predict(“a”) -> “person
  predict(“am”) -> “a”
  
第三轮

Given a list of strings, a keyword, and an int N, print the words that are within distance N of the keyword
E.g. [“it”, “a”, “b”, “c”, “it”, “a”, “b”], keyword = “it”, N = 3
Output
it
a
b
c
it
a
b
followup: list变成stream

第四轮

先问了个简历上的BQ

Given an undirected graph that is also a ring that contains all vertices, find the ring
E.g. {0: [1,3], 1: [2, 0], 2:[1,3], 3:[0, 2]}, output [0,1,2,3] or [1,2,3,0] or [2,3,0,1] ….
感觉大部分‍‌‍‌‍‌‌‍‌‍‍‌‍‍‍‍‌‌时间都在写/讨论怎么check invalid input...

第五轮

面试官no show，过了几个小时回了email说有emergency...
求米！
